{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Bild](img/ex66.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cliff- Example: \n",
    "* Episodic Task\n",
    "* Simple Grid-World\n",
    "* States are Grid-Positions\n",
    "* Available actions are King-Moves\n",
    "* Each step (not falling down the cliff) has a reward of R = -1\n",
    "* Reaching the Goal has a reward of 0\n",
    "* Walking down the cliff resets the position back to the start S with reward R = -100\n",
    "\n",
    "### Note\n",
    "* In the Pseudocode for n-step TD States and Rewards get stored in a Datastructure that takes their indexes $\\% (n+1)$ - Right now I just store the whole sequence. Shouldn't be a difficult change, just put in some $\\%$ operator everytime we access or store something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cliff:\n",
    "    '''Class defining the environment'''\n",
    "    def __init__(self, shapex, shapey, holes, start, goal):\n",
    "        self.shapex = shapex\n",
    "        self.shapey = shapey\n",
    "        self.holes  = holes\n",
    "        self.start  = start\n",
    "        self.goal   = goal\n",
    "        \n",
    "        self.bitmap = self.build_bitmap()\n",
    "        \n",
    "    def build_bitmap(self):\n",
    "        '''builds the bitmap for visualisation'''\n",
    "        bitmap = np.ones((self.shapex, self.shapey))\n",
    "        \n",
    "        for hole in holes:\n",
    "            bitmap[hole] = 0\n",
    "        \n",
    "        return bitmap\n",
    "    \n",
    "    def show_bitmap(self):\n",
    "        '''shows the environment of holes and walkable path'''\n",
    "        \n",
    "        plt.imshow(self.bitmap)\n",
    "    \n",
    "    def show_path(self, path):\n",
    "        '''\n",
    "        path : list(tuple(int, int)) : sequence of states\n",
    "        \n",
    "        plots a given path onto the bitmap\n",
    "        '''\n",
    "        \n",
    "        c0 = 5\n",
    "        c1 = 6\n",
    "        \n",
    "        length    = len(path)\n",
    "        map_      = self.bitmap.copy()\n",
    "        fade      = np.linspace(c0, c1, num=length)\n",
    "        \n",
    "        for i in range(length):\n",
    "            map_[path[i]] = fade[i]\n",
    "            \n",
    "        map_[self.start] = c0\n",
    "        map_[self.goal]  = c1\n",
    "        \n",
    "        print(f\"path length: {len(path)}\")\n",
    "        plt.imshow(map_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "shapex = 5\n",
    "shapey = 10\n",
    "start  = (4, 0)\n",
    "goal   = (4, 9)\n",
    "holes  = [(4, 1), (4, 2), (4, 3), (4, 4), (4, 5), (4, 6), (4, 7), (4, 8)]\n",
    "#, (3, 5), (2, 5), (2, 4), (2, 3), (2, 7), (1, 7)]\n",
    "\n",
    "cliff  = Cliff(shapex, shapey, holes, start, goal)\n",
    "cliff.show_bitmap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "moves    = [(-1, -1), (-1, 0), (-1, 1), (0, -1), (0, 1), (1, -1), (1, 0), (1, 1)]\n",
    "move_idx = {moves[i] : i for i in range(len(moves))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move(map_, pos, act):\n",
    "    '''\n",
    "    map_   : Cliff           : Environment\n",
    "    pos    : tuple(int, int) : Position in Environment\n",
    "    act    : tuple(int, int) : Move direction\n",
    "    \n",
    "    Move from pos in direction act\n",
    "    \n",
    "    newpos : tuple(int, int) : New position\n",
    "    '''\n",
    "    \n",
    "    fallen = False\n",
    "    \n",
    "    # Clamp values to map\n",
    "    x_pos  = int(max(0, min(map_.shapex - 1, pos[0] + act[0])))\n",
    "    y_pos  = int(max(0, min(map_.shapey - 1, pos[1] + act[1])))\n",
    "    newpos = (x_pos, y_pos)\n",
    "    \n",
    "    # Reset position if falling in hole\n",
    "    if newpos in map_.holes:\n",
    "        newpos = map_.start\n",
    "        fallen = True\n",
    "    \n",
    "    return newpos, fallen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n-Step TD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbors(map_, pos):\n",
    "    '''\n",
    "    map_      : Cliff                 : Environment\n",
    "    pos       : tuple(int, int)       : Position in Environment\n",
    "    \n",
    "    Get neighboring states of position pos\n",
    "    \n",
    "    neighbors : list(tuple(int, int)) : list of positions\n",
    "    '''\n",
    "    global moves\n",
    "    \n",
    "    neighbors = []\n",
    "    \n",
    "    for act in moves:\n",
    "        neighbors.append(move(map_, pos, act)[0])\n",
    "    \n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy_policy_V(V, map_, pos, epsilon=0.1):\n",
    "    '''\n",
    "    V         : 2d np.array(), float : State values\n",
    "    map_      : Cliff                : Environment\n",
    "    pos       : tuple(int, int)      : Position in Environment\n",
    "    epsilon   : float in [0, 1]      : Exploration / Exploitation Parameter\n",
    "    \n",
    "    Epsilon Greedy Policy. For a low epsilon value : high exploitation, low exploration\n",
    "    \n",
    "              : tuple(int, int)      : Decided Action according to policy\n",
    "    '''\n",
    "    \n",
    "    global moves\n",
    "    \n",
    "    act_i = None\n",
    "    r     = np.random.rand()\n",
    "    \n",
    "    neighbors   = get_neighbors(map_, pos)\n",
    "    V_neighbors = [V[n_pos] for n_pos in neighbors]\n",
    "    \n",
    "    if r > epsilon:\n",
    "        act_i = np.argmax(V_neighbors)\n",
    "    else:\n",
    "        act_i = np.random.randint(len(moves))\n",
    "        \n",
    "    return moves[act_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_step_td(map_, alpha, n, episodes, epsilon=0.1, gamma=1):\n",
    "    '''\n",
    "    alpha    : float in (0, 1]      : Learning rate\n",
    "    n        : int                  : How many steps ahead we look\n",
    "    episodes : int                  : Amount of episodes we train for\n",
    "    epsilon  : float in [0, 1]      : Epsilon parameter for epsilon-greedy policy\n",
    "    gamma    : float in [0, 1]      : Discount rate\n",
    "     \n",
    "    n-step temporal difference method to estimate V\n",
    "    \n",
    "    V        : 2d np.array(), float : State values\n",
    "    '''\n",
    "    \n",
    "    V = np.zeros((map_.shapex, map_.shapey))\n",
    "    \n",
    "    for episode in range(episodes):\n",
    "        t = 0\n",
    "        s = map_.start\n",
    "        \n",
    "        T = np.inf\n",
    "        S = [s]\n",
    "        R = []\n",
    "        \n",
    "        while True:\n",
    "            # Take next step\n",
    "            if t < T:\n",
    "                A          = epsilon_greedy_policy_V(V, map_, s, epsilon=epsilon)\n",
    "                sn, fallen = move(map_, s, A)\n",
    "                \n",
    "                r = -1\n",
    "                if fallen:\n",
    "                    r = -100\n",
    "                elif sn == map_.goal:\n",
    "                    r = 0\n",
    "                    T = t + 1\n",
    "                \n",
    "                S.append(sn)\n",
    "                R.append(r)\n",
    "                s = sn\n",
    "            \n",
    "            # Time which will get updated this step \n",
    "            tau = t - n + 1\n",
    "            \n",
    "            # Update State Values\n",
    "            if tau >= 0:\n",
    "                \n",
    "                G = sum([gamma**(i - tau - 1) * R[i] for i in range(tau + 1, min(tau + n, T))])\n",
    "                \n",
    "                if tau + n < T:\n",
    "                    G += gamma**n * V[S[tau + n]]\n",
    "                    \n",
    "                V[S[tau]] += alpha * (G - V[S[tau]])\n",
    "            \n",
    "            t += 1\n",
    "            \n",
    "            # Episode over\n",
    "            if tau == T - 1:\n",
    "                break\n",
    "    \n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trace_V(map_, V):\n",
    "    '''\n",
    "    map_    : Cliff                 : Current environment\n",
    "    V       : 2d np.array(), float  : State values\n",
    "    \n",
    "    Records Greedy Path from Cliff.start\n",
    "    \n",
    "    path    : list(tuple(int, int)) : States visited'''\n",
    "    \n",
    "    global moves\n",
    "    \n",
    "    S = map_.start\n",
    "    A = epsilon_greedy_policy_V(V, map_, S, epsilon=0.0)\n",
    "    path = []\n",
    "    \n",
    "    while S != map_.goal:\n",
    "        path.append(S)\n",
    "        Sn, _ = move(map_, S, A)\n",
    "        An = epsilon_greedy_policy_V(V, map_, Sn, epsilon=0.0)\n",
    "        S  = Sn\n",
    "        A  = An\n",
    "        \n",
    "        if Sn == map_.start or Sn in path:\n",
    "            print(\"State Values dont create greedy path\")\n",
    "            break\n",
    "    \n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n-Step TD Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### n=2, 2000 Episodes\n",
    "Suboptimal, but at least we can traverse V with a simple greedy policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path length: 10\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "V    = n_step_td(cliff, 0.5, 2, 2000)\n",
    "path = trace_V(cliff, V)\n",
    "cliff.show_path(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5c6d0ee520>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n-Step SARSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy_policy_Q(Q, map_, pos, epsilon=0.1):\n",
    "    '''\n",
    "    Q         : 3d np.array(), float : State-Action values\n",
    "    map_      : Cliff                : Environment\n",
    "    pos       : tuple(int, int)      : Position in Environment\n",
    "    epsilon   : float in [0, 1]      : Exploration / Exploitation Parameter\n",
    "    \n",
    "    Epsilon Greedy Policy. For a low epsilon value : high exploitation, low exploration\n",
    "    \n",
    "              : tuple(int, int)      : Decided Action according to policy\n",
    "    '''\n",
    "    \n",
    "    global moves\n",
    "    \n",
    "    act_i = None\n",
    "    r     = np.random.rand()\n",
    "        \n",
    "    if r > epsilon:\n",
    "        act_i = np.argmax(Q[pos])\n",
    "    else:\n",
    "        act_i = np.random.randint(len(moves))\n",
    "        \n",
    "    return moves[act_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_step_sarsa(map_, alpha, n, episodes, epsilon=0.1, gamma=1):\n",
    "    '''\n",
    "    alpha    : float in (0, 1]      : Learning rate\n",
    "    n        : int                  : How many steps ahead we look\n",
    "    episodes : int                  : Amount of episodes we train for\n",
    "    epsilon  : float in [0, 1]      : Epsilon parameter for epsilon-greedy policy\n",
    "    gamma    : float in [0, 1]      : Discount rate\n",
    "     \n",
    "    n-step temporal difference method to estimate V\n",
    "    \n",
    "    Q        : 3d np.array(), float : State-Action values\n",
    "    '''\n",
    "    \n",
    "    global moves\n",
    "    \n",
    "    Q = np.zeros((map_.shapex, map_.shapey, len(moves)))\n",
    "    \n",
    "    for episode in range(episodes):\n",
    "        t = 0\n",
    "        s = map_.start\n",
    "        \n",
    "        T = np.inf\n",
    "        S = [s]\n",
    "        R = []\n",
    "        A = [epsilon_greedy_policy_Q(Q, map_, s, epsilon=epsilon)]\n",
    "        \n",
    "        while True:\n",
    "            # Take next step\n",
    "            if t < T:\n",
    "                sn, fallen = move(map_, s, A[-1])\n",
    "                \n",
    "                r = -1\n",
    "                if fallen:\n",
    "                    r = -100\n",
    "                    \n",
    "                if sn == map_.goal:\n",
    "                    r = 0\n",
    "                    T = t + 1\n",
    "                else:\n",
    "                    A.append(epsilon_greedy_policy_Q(Q, map_, sn, epsilon=epsilon))\n",
    "                \n",
    "                S.append(sn)\n",
    "                R.append(r)\n",
    "                s = sn\n",
    "            \n",
    "            # Time which will get updated this step \n",
    "            tau = t - n + 1\n",
    "            \n",
    "            # Update State Values\n",
    "            if tau >= 0:\n",
    "                \n",
    "                G = sum([gamma**(i - tau - 1) * R[i] for i in range(tau + 1, min(tau + n, T))])\n",
    "                \n",
    "                if tau + n < T:\n",
    "                    idx_tn = (S[tau + n][0], S[tau + n][1], move_idx[A[tau + n]])\n",
    "                    G += gamma**n * Q[idx_tn]\n",
    "                    \n",
    "                idx_t = (S[tau][0], S[tau][1], move_idx[A[tau]])\n",
    "                Q[idx_t] += alpha * (G - Q[idx_t])\n",
    "            \n",
    "            t += 1\n",
    "            \n",
    "            # Episode over\n",
    "            if tau == T - 1:\n",
    "                break\n",
    "    \n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trace_Q(map_, Q):\n",
    "    '''\n",
    "    map_    : Cliff                 : Current environment\n",
    "    Q       : 3d np.array(), float  : State-Action values\n",
    "    \n",
    "    Records Greedy Path from grid-start\n",
    "    \n",
    "    path    : list(tuple(int, int)) : States visited until termination\n",
    "    '''\n",
    "    \n",
    "    global moves\n",
    "    \n",
    "    S = map_.start\n",
    "    A = moves[np.argmax(Q[S])]\n",
    "    path = []\n",
    "    \n",
    "    while S != map_.goal:\n",
    "        path.append(S)\n",
    "        Sn, _ = move(map_, S, A)\n",
    "        An    = moves[np.argmax(Q[Sn])]\n",
    "        S     = Sn\n",
    "        A     = An\n",
    "        \n",
    "        if Sn == map_.start or Sn in path:\n",
    "            print(\"State Values dont create greedy path\")\n",
    "            break\n",
    "    \n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path length: 14\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Q    = n_step_sarsa(cliff, 0.5, 2, 8000)\n",
    "path = trace_Q(cliff, Q)\n",
    "cliff.show_path(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
